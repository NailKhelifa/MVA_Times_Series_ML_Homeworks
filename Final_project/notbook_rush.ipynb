{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter\n",
    "import scipy.stats as stats # for the breakpoints in SAX\n",
    "from scipy.stats import norm\n",
    "from dtw import dtw\n",
    "import os\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "##Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "## TSLEARN\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "## Custom : code implémenté par nous-même\n",
    "from Symbol import SYMBOLS\n",
    "from SFA import *\n",
    "from ASTRIDE import *\n",
    "from SAX_transf import *\n",
    "from distances import MINDIST, TRENDIST\n",
    "import utils\n",
    "import warnings \n",
    "import sax_clustering\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG200_X_train, ECG200_x_train, ECG200_y_train, ECG200_X_test, ECG200_x_test, ECG200_y_test = utils.generate_data(type=\"ECG200\")\n",
    "acsf1_X_train, acsf1_x_train, acsf1_y_train, acsf1_X_test, acsf1_x_test, acsf1_y_test = utils.generate_data(type=\"acsf1\")\n",
    "catsanddogs_X_train, catsanddogs_x_train, catsanddogs_y_train, catsanddogs_X_test, catsanddogs_x_test, catsanddogs_y_test = utils.generate_data(type=\"catsanddogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_sax(sax, max_iter, num_cluster):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme K-Means adapté pour des observations sous forme de chaînes.\n",
    "\n",
    "    Parameters:\n",
    "    sax (SYMBOLS): comme rendu par SYMBOLS()\n",
    "    max_iter (int): Nombre maximum d'itérations.\n",
    "    num_cluster (int): Nombre de clusters à former.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Un tuple contenant :\n",
    "        - Les indices des centres finaux des clusters (list).\n",
    "        - Les labels des clusters pour chaque observation (np.ndarray de taille (n,)).\n",
    "        - La distance intra-cluster moyenne (float).\n",
    "        - La distance inter-cluster moyenne (float).\n",
    "    \"\"\"\n",
    "    data = sax.symbolized_x_train.iloc[1,:]\n",
    "\n",
    "    # Choix de la mesure de distance\n",
    "    if sax.method == \"TSAX\":\n",
    "        dist = TRENDIST(sax.alphabet_size, sax.train_ts_length, sax.angle_breakpoint_alphabet_size)\n",
    "    else:\n",
    "        dist = MINDIST(sax.alphabet_size, sax.train_ts_length)\n",
    "\n",
    "    # Étape 1 : Initialisation\n",
    "    num_samples = data.shape[0]  # nombre d'observations\n",
    "    np.random.seed(42)  # Pour la reproductibilité\n",
    "    initial_indices = np.random.choice(num_samples, num_cluster, replace=False)\n",
    "    centroids = initial_indices  # Les centroïdes sont initialisés par des indices\n",
    "\n",
    "    # Initialiser les labels des clusters (0, 1, ..., num_cluster-1)\n",
    "    labels = np.zeros(num_samples, dtype=int)\n",
    "\n",
    "    # Boucle principale de l'algorithme K-Means\n",
    "    for iteration in range(max_iter):\n",
    "        # Étape 2 : Assignation des observations aux clusters les plus proches\n",
    "        for i in range(num_samples):\n",
    "            distances = []\n",
    "            for centroid_idx in centroids:\n",
    "                if sax.method == \"TSAX\":\n",
    "                    distances.append(dist.tsax_mindist(data.iloc[i], data.iloc[centroid_idx]))\n",
    "                else:\n",
    "                    distances.append(dist.mindist(data.iloc[i], data.iloc[centroid_idx]))\n",
    "            # Trouver le centroïde le plus proche et assigner l'observation à ce cluster\n",
    "            labels[i] = np.argmin(distances)\n",
    "\n",
    "        # Étape 3 : Mise à jour des centroïdes\n",
    "        new_centroids = []\n",
    "        for k in range(num_cluster):\n",
    "            # Extraire les indices des observations appartenant au cluster k\n",
    "            cluster_indices = np.where(labels == k)[0]\n",
    "            if len(cluster_indices) > 0:\n",
    "                # Trouver le point le plus central dans le cluster\n",
    "                min_distance_sum = float(\"inf\")\n",
    "                central_index = cluster_indices[0]\n",
    "                for idx in cluster_indices:\n",
    "                    # Calculer la somme des distances de ce point à tous les autres du cluster\n",
    "                    distance_sum = 0\n",
    "                    for other_idx in cluster_indices:\n",
    "                        if sax.method == \"TSAX\":\n",
    "                            distance_sum += dist.tsax_mindist(data.iloc[idx], data.iloc[other_idx])\n",
    "                        else:\n",
    "                            distance_sum += dist.mindist(data.iloc[idx], data.iloc[other_idx])\n",
    "                    # Mettre à jour le point central si une plus petite somme est trouvée\n",
    "                    if distance_sum < min_distance_sum:\n",
    "                        min_distance_sum = distance_sum\n",
    "                        central_index = idx\n",
    "                new_centroids.append(central_index)\n",
    "            else:\n",
    "                # Si un cluster est vide, réinitialiser son centroïde de manière aléatoire\n",
    "                new_centroids.append(np.random.choice(num_samples))\n",
    "\n",
    "        # Vérifier la convergence\n",
    "        if np.array_equal(centroids, new_centroids):\n",
    "            print(f\"Convergence atteinte après {iteration + 1} itérations.\")\n",
    "            break\n",
    "        \n",
    "        # Mettre à jour les centroïdes pour la prochaine itération\n",
    "        centroids = new_centroids\n",
    "\n",
    "    # Calcul de la distance intra-cluster moyenne\n",
    "    intra_cluster_distances = []\n",
    "    for k in range(num_cluster):\n",
    "        cluster_indices = np.where(labels == k)[0]\n",
    "        for idx in cluster_indices:\n",
    "            if sax.method == \"TSAX\":\n",
    "                intra_cluster_distances.append(dist.tsax_mindist(data.iloc[idx], data.iloc[centroids[k]]))\n",
    "            else:\n",
    "                intra_cluster_distances.append(dist.mindist(data.iloc[idx], data.iloc[centroids[k]]))\n",
    "    intra_cluster_mean_distance = np.mean(intra_cluster_distances) if intra_cluster_distances else 0.0\n",
    "\n",
    "    # Calcul de la distance inter-cluster moyenne\n",
    "    inter_cluster_distances = []\n",
    "    for i in range(num_cluster):\n",
    "        for j in range(i + 1, num_cluster):\n",
    "            if sax.method == \"TSAX\":\n",
    "                inter_cluster_distances.append(\n",
    "                    dist.tsax_mindist(data.iloc[centroids[i]], data.iloc[centroids[j]])\n",
    "                )\n",
    "            else:\n",
    "                inter_cluster_distances.append(\n",
    "                    dist.mindist(data.iloc[centroids[i]], data.iloc[centroids[j]])\n",
    "                )\n",
    "    inter_cluster_mean_distance = np.mean(inter_cluster_distances) if inter_cluster_distances else 0.0\n",
    "\n",
    "    return centroids, labels, intra_cluster_mean_distance, inter_cluster_mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence atteinte après 2 itérations.\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "SAX_list_k_means_intra_cluster = []\n",
    "SAX_list_k_means_inter_cluster = []\n",
    "sax = SYMBOLS(catsanddogs_x_train, \n",
    "              catsanddogs_x_test, \n",
    "              'TSAX', \n",
    "              num_segments=10, \n",
    "              alphabet_size=10)\n",
    "\n",
    "for k in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20]:\n",
    "    _, _, intra_cluster_mean_distance, inter_cluster_mean_distance = k_means_sax(sax, 20, k)\n",
    "    SAX_list_k_means_inter_cluster.append(inter_cluster_mean_distance)\n",
    "    SAX_list_k_means_intra_cluster.append(intra_cluster_mean_distance)\n",
    "    print('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ECG200_k_means_1_20_intra_cluster_TSAX\", SAX_list_k_means_intra_cluster)\n",
    "np.save(\"ECG200_k_means_1_20_inter_cluster_TSAX\", SAX_list_k_means_inter_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataframes in a dictionnary\n",
    "typical_df = {\n",
    "    \"ECG200\": (ECG200_x_train, ECG200_x_test),\n",
    "    \"ACSF1\": (acsf1_x_train,acsf1_x_test),\n",
    "    \"Cats and Dogs\": (catsanddogs_x_train, catsanddogs_x_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (df_name, df) in enumerate(typical_df.items()):\n",
    "    list_intra_cluster = f\"{df_name}_list_k_means_intra_cluster\"\n",
    "    list_inter_cluster = f\"{df_name}_list_k_means_inter_cluster\"\n",
    "    SAX_list_k_means_intra_cluster = []\n",
    "    SAX_list_k_means_inter_cluster = []\n",
    "    sax = SYMBOLS(df[0], \n",
    "                  df[1], \n",
    "                  'SAX', \n",
    "                  num_segments=10, \n",
    "                  alphabet_size=10)\n",
    "\n",
    "    for k in [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]:\n",
    "        _, _, intra_cluster_mean_distance, inter_cluster_mean_distance = k_means_sax(sax, 30, k)\n",
    "        SAX_list_k_means_inter_cluster.append(inter_cluster_mean_distance)\n",
    "        SAX_list_k_means_intra_cluster.append(intra_cluster_mean_distance)\n",
    "        np.save(list_intra_cluster, SAX_list_k_means_intra_cluster)\n",
    "        np.save(list_inter_cluster, SAX_list_k_means_inter_cluster)\n",
    "        print('*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nail_env)",
   "language": "python",
   "name": "nail_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
